{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400731dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/DataforPractice/JapMedia/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae68b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ì œëª©</th>\n",
       "      <th>ë³¸ë¬¸</th>\n",
       "      <th>ì£¼ìš” í‚¤ì›Œë“œ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ì¡ì´ˆì—ë§Œ ë†ì•½ ë¶„ì‚¬, ìˆ²ì²˜ëŸ¼ ë§Œë“  ì „ì‹œê´€â€¦ ì˜¬í•´ CESëŠ” ì˜¨í†µ ì´ˆë¡ë¹›</td>\n",
       "      <td>ì†Œê³ ê¸°ë¥¼ ëŒ€ì²´í•˜ëŠ” ê³°íŒ¡ì´ ë‹¨ë°±ì§ˆ, ì¡ì´ˆë§Œ ì½• ì§‘ì–´ ì œì´ˆì œë¥¼ ë¶„ì‚¬í•˜ëŠ” ë¡œë´‡, ë‚˜ë¬´ì°Œêº¼...</td>\n",
       "      <td>CES, ì¹œí™˜ê²½, ì²¨ë‹¨ ê¸°ìˆ , ê¸€ë¡œë²Œ ê¸°ì—…ë“¤, ì†Œë¹„ì í™˜ê²½ ì‡¼, êµ­ë‚´ ê¸°ì—…, ì¹œí™˜ê²½...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EU, ë…¹ìƒ‰ íˆ¬ìì— ì›ìë ¥ í¬í•¨â€¦ ç¾Â·æ—¥, ì†Œí˜•ì›ì „ ê³µë™ ê°œë°œ</td>\n",
       "      <td>2022ë…„ ìƒˆí•´ ë²½ë‘ë¶€í„° ì „ ì„¸ê³„ê°€ ì›ìë ¥ ë°œì „ì— ì£¼ëª©í•˜ê³  ìˆë‹¤. ê¸°í›„ë³€í™”ì˜ ì£¼ë²”ì¸...</td>\n",
       "      <td>ì›ìë ¥, ë°œì „, ì´ì‚°í™”íƒ„ì†Œ, ë°œìƒ, í˜„ì‹¤ ì¸ì‹, ìœ ëŸ½ì—°í•©, EU, ë…¹ìƒ‰ íˆ¬ì, ê·¸ë¦°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[ì´ì˜ì™„ì˜ ì‚¬ì´ì–¸ìŠ¤ì¹´í˜] ê´´í…Œê°€ ì‚¬ë‘í•œ í‘ë§¥ì£¼, ë¦´ì¼€ê°€ ì¦ê¸´ í•„ìŠ¤ë„ˆâ€¦ ê¸°í›„ë³€í™”ë¡œ ì‚¬ë¼ì§ˆê¹Œ</td>\n",
       "      <td>ì§€ë‚œí•´ ì˜¥ìŠ¤í¼ë“œ ì˜ì–´ì‚¬ì „ì— â€˜ì¹˜ë§¥â€™ì´ë€ ë‹¨ì–´ê°€ ì˜¬ë¼ê°”ë‹¤. ë§¥ì£¼ í•˜ë©´ ì¹˜í‚¨ì´ë¼ëŠ” ë§ì´...</td>\n",
       "      <td>ë§¥ì£¼, ì›ë£Œ, í™‰, ë³´ë¦¬ ì¬ë°°, ì§ê²©íƒ„, ì˜¨ë‚œí™”, ê·¹ì‹¬í•œ ê°€ë­„, ë†ì‚¬, íƒ€ê²©, í•­ìƒ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ì‘ë…„ì—” ì „ê¸°ì°¨, ì˜¬í•´ëŠ” ë©”íƒ€ë²„ìŠ¤â€¦ ETFì˜ ì§ˆì£¼</td>\n",
       "      <td>ì§€ë‚œí•´ ìƒì¥ì§€ìˆ˜í€ë“œ(ETF) ì‹œì¥ì€ ìƒˆë¡­ê²Œ íƒœì–´ë‚¬ë‹¤ëŠ” í‰ê°€ë¥¼ ë°›ëŠ”ë‹¤. ê·¸ ì „ì—ëŠ” ì½”...</td>\n",
       "      <td>ETF ì‹œì¥, ì¹œí™˜ê²½, ë©”íƒ€ë²„ìŠ¤, í•´ì™¸, íƒ„ì†Œë°°ì¶œê¶Œ, íˆ¬ì, ìœ ëŸ½, ì¤‘êµ­, ì „ê¸°ì°¨ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IAEA â€œì „ì„¸ê³„ ì›ì „ 20ë…„ë‚´ 100ê¸° ë” ê±´ì„¤â€</td>\n",
       "      <td>íƒ„ì†Œ ì¤‘ë¦½ íë¦„ ì†ì— ì—ë„ˆì§€ ìœ„ê¸°ê¹Œì§€ ë‹¥ì¹˜ì, ì¬ìƒì—ë„ˆì§€ ì•½ì ì„ ë³´ì™„í•  ì—ë„ˆì§€ì›ìœ¼ë¡œ...</td>\n",
       "      <td>ì¬ìƒì—ë„ˆì§€, ì•½ì , ë³´ì™„, ì—ë„ˆì§€ì›, ì›ì „, ì£¼ëª©, IAEA, ì¶”ê°€ ê±´ì„¤, ì œì•ˆ, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                 ì œëª©  \\\n",
       "0   0             ì¡ì´ˆì—ë§Œ ë†ì•½ ë¶„ì‚¬, ìˆ²ì²˜ëŸ¼ ë§Œë“  ì „ì‹œê´€â€¦ ì˜¬í•´ CESëŠ” ì˜¨í†µ ì´ˆë¡ë¹›   \n",
       "1   1                 EU, ë…¹ìƒ‰ íˆ¬ìì— ì›ìë ¥ í¬í•¨â€¦ ç¾Â·æ—¥, ì†Œí˜•ì›ì „ ê³µë™ ê°œë°œ   \n",
       "2   2  [ì´ì˜ì™„ì˜ ì‚¬ì´ì–¸ìŠ¤ì¹´í˜] ê´´í…Œê°€ ì‚¬ë‘í•œ í‘ë§¥ì£¼, ë¦´ì¼€ê°€ ì¦ê¸´ í•„ìŠ¤ë„ˆâ€¦ ê¸°í›„ë³€í™”ë¡œ ì‚¬ë¼ì§ˆê¹Œ   \n",
       "3   3                         ì‘ë…„ì—” ì „ê¸°ì°¨, ì˜¬í•´ëŠ” ë©”íƒ€ë²„ìŠ¤â€¦ ETFì˜ ì§ˆì£¼   \n",
       "4   4                       IAEA â€œì „ì„¸ê³„ ì›ì „ 20ë…„ë‚´ 100ê¸° ë” ê±´ì„¤â€   \n",
       "\n",
       "                                                  ë³¸ë¬¸  \\\n",
       "0  ì†Œê³ ê¸°ë¥¼ ëŒ€ì²´í•˜ëŠ” ê³°íŒ¡ì´ ë‹¨ë°±ì§ˆ, ì¡ì´ˆë§Œ ì½• ì§‘ì–´ ì œì´ˆì œë¥¼ ë¶„ì‚¬í•˜ëŠ” ë¡œë´‡, ë‚˜ë¬´ì°Œêº¼...   \n",
       "1  2022ë…„ ìƒˆí•´ ë²½ë‘ë¶€í„° ì „ ì„¸ê³„ê°€ ì›ìë ¥ ë°œì „ì— ì£¼ëª©í•˜ê³  ìˆë‹¤. ê¸°í›„ë³€í™”ì˜ ì£¼ë²”ì¸...   \n",
       "2  ì§€ë‚œí•´ ì˜¥ìŠ¤í¼ë“œ ì˜ì–´ì‚¬ì „ì— â€˜ì¹˜ë§¥â€™ì´ë€ ë‹¨ì–´ê°€ ì˜¬ë¼ê°”ë‹¤. ë§¥ì£¼ í•˜ë©´ ì¹˜í‚¨ì´ë¼ëŠ” ë§ì´...   \n",
       "3  ì§€ë‚œí•´ ìƒì¥ì§€ìˆ˜í€ë“œ(ETF) ì‹œì¥ì€ ìƒˆë¡­ê²Œ íƒœì–´ë‚¬ë‹¤ëŠ” í‰ê°€ë¥¼ ë°›ëŠ”ë‹¤. ê·¸ ì „ì—ëŠ” ì½”...   \n",
       "4  íƒ„ì†Œ ì¤‘ë¦½ íë¦„ ì†ì— ì—ë„ˆì§€ ìœ„ê¸°ê¹Œì§€ ë‹¥ì¹˜ì, ì¬ìƒì—ë„ˆì§€ ì•½ì ì„ ë³´ì™„í•  ì—ë„ˆì§€ì›ìœ¼ë¡œ...   \n",
       "\n",
       "                                              ì£¼ìš” í‚¤ì›Œë“œ  \n",
       "0  CES, ì¹œí™˜ê²½, ì²¨ë‹¨ ê¸°ìˆ , ê¸€ë¡œë²Œ ê¸°ì—…ë“¤, ì†Œë¹„ì í™˜ê²½ ì‡¼, êµ­ë‚´ ê¸°ì—…, ì¹œí™˜ê²½...  \n",
       "1  ì›ìë ¥, ë°œì „, ì´ì‚°í™”íƒ„ì†Œ, ë°œìƒ, í˜„ì‹¤ ì¸ì‹, ìœ ëŸ½ì—°í•©, EU, ë…¹ìƒ‰ íˆ¬ì, ê·¸ë¦°...  \n",
       "2  ë§¥ì£¼, ì›ë£Œ, í™‰, ë³´ë¦¬ ì¬ë°°, ì§ê²©íƒ„, ì˜¨ë‚œí™”, ê·¹ì‹¬í•œ ê°€ë­„, ë†ì‚¬, íƒ€ê²©, í•­ìƒ...  \n",
       "3  ETF ì‹œì¥, ì¹œí™˜ê²½, ë©”íƒ€ë²„ìŠ¤, í•´ì™¸, íƒ„ì†Œë°°ì¶œê¶Œ, íˆ¬ì, ìœ ëŸ½, ì¤‘êµ­, ì „ê¸°ì°¨ ...  \n",
       "4  ì¬ìƒì—ë„ˆì§€, ì•½ì , ë³´ì™„, ì—ë„ˆì§€ì›, ì›ì „, ì£¼ëª©, IAEA, ì¶”ê°€ ê±´ì„¤, ì œì•ˆ, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_excel(dir+\"data/kor_data/ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°.xlsx\")\n",
    "dat.insert(0, 'id', dat.index)\n",
    "dat = dat.filter(['id','ì œëª©','ë³¸ë¬¸','ì£¼ìš” í‚¤ì›Œë“œ'])\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e524912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Script Start (Processing ALL .xlsx files in folder) ---\n",
      "Config: MODEL=llama3:8b\n",
      "Target Directory: E:/DataforPractice/JapMedia/data\\kor_data\n",
      "Found 6 files to process:\n",
      "  - ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°.xlsx\n",
      "  - ì¡°ì„ ì¼ë³´_2023ë…„ë„ ë°ì´í„°.xlsx\n",
      "  - ì¡°ì„ ì¼ë³´_2024ë…„ë„ ë°ì´í„°.xlsx\n",
      "  - í•œê²¨ë ˆ_2022ë…„ë„ ë°ì´í„°.xlsx\n",
      "  - í•œê²¨ë ˆ_2023ë…„ë„ ë°ì´í„°.xlsx\n",
      "  - í•œê²¨ë ˆ_2024ë…„ë„ ë°ì´í„°.xlsx\n",
      "\n",
      "========================================================\n",
      "Processing File: ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°.xlsx\n",
      "Output to: E:/DataforPractice/JapMedia/data\\kor_data\\ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°_translated.csv\n",
      "========================================================\n",
      "Opening Excel file (read_only): ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°.xlsx ...\n",
      "Reading header...\n",
      "Initializing row iterator...\n",
      "âœ… Excel file loaded successfully. Starting row-by-row processing loop...\n",
      "Output file header written to E:/DataforPractice/JapMedia/data\\kor_data\\ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°_translated.csv\n",
      "\n",
      "--- Processing ì¡°ì„ ì¼ë³´_2022ë…„ë„ ë°ì´í„°.xlsx - Row ID: 1 ---\n",
      "  - Translating 'ì œëª©'...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import traceback\n",
    "import os\n",
    "import openpyxl \n",
    "import glob  # ğŸ‘ˆ (íŒŒì¼ ëª©ë¡ ê²€ìƒ‰ì„ ìœ„í•´ ì¶”ê°€)\n",
    "from typing import List, Optional\n",
    "\n",
    "# --- 1. ê¸°ë³¸ ì„¤ì • ---\n",
    "dir = \"E:/DataforPractice/JapMedia/\"\n",
    "MODEL = \"llama3:8b\" # \"gpt-oss:20b\" \n",
    "ERROR_LOG_PATH = \"translation_error_log.txt\"\n",
    "\n",
    "KOR_DATA_DIR = os.path.join(dir, \"data\", \"kor_data\")\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert translator specializing in Korean-to-English news articles. \"\n",
    "    \"You will be given a single Korean string. \"\n",
    "    \"Your task is to translate it into professional, journalistic English.\\n\"\n",
    "    \"- Maintain a neutral and objective tone.\\n\"\n",
    "    \"- Respond ONLY with the single, translated English string. \"\n",
    "    \"- Do not include any other text, explanations, or JSON formatting.\"\n",
    ")\n",
    "\n",
    "def translate_single(text: str) -> str:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\" \n",
    "\n",
    "    try:\n",
    "        resp = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            options={\"temperature\": 0.1, \"num_ctx\": 4096},\n",
    "        )\n",
    "        return resp['message']['content'].strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    - ERROR: Translation failed for text. {e}\")\n",
    "        with open(ERROR_LOG_PATH, \"a\", encoding='utf-8') as f:\n",
    "            f.write(f\"Translation Error: {e}\\nInput Text: {text[:50]}...\\n\\n\")\n",
    "        return \"ERROR: Translation failed\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Script Start (Processing ALL .xlsx files in folder) ---\")\n",
    "    print(f\"Config: MODEL={MODEL}\")\n",
    "    print(f\"Target Directory: {KOR_DATA_DIR}\")\n",
    "\n",
    "    search_path = os.path.join(KOR_DATA_DIR, \"*.xlsx\")\n",
    "    all_excel_files = [f for f in glob.glob(search_path) if not os.path.basename(f).startswith(\"~$\")]\n",
    "\n",
    "    if not all_excel_files:\n",
    "        print(f\"!!!!!!!! ERROR: No .xlsx files found in {KOR_DATA_DIR} !!!!!!!!\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Found {len(all_excel_files)} files to process:\")\n",
    "    for f in all_excel_files:\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "    for input_file_path in all_excel_files:\n",
    "        \n",
    "        file_basename = os.path.basename(input_file_path)\n",
    "        file_name_without_ext = os.path.splitext(file_basename)[0]\n",
    "        \n",
    "        output_file_name = f\"{file_name_without_ext}_translated.csv\"\n",
    "        output_file_path = os.path.join(KOR_DATA_DIR, output_file_name) \n",
    "\n",
    "        print(f\"\\n========================================================\")\n",
    "        print(f\"Processing File: {file_basename}\")\n",
    "        print(f\"Output to: {output_file_path}\")\n",
    "        print(f\"========================================================\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Opening Excel file (read_only): {file_basename} ...\")\n",
    "            workbook = openpyxl.load_workbook(input_file_path, read_only=True)\n",
    "            sheet = workbook.active\n",
    "            \n",
    "            print(\"Reading header...\")\n",
    "            header = [cell.value for cell in sheet[1]]\n",
    "            \n",
    "            translated_headers = []\n",
    "            cols_to_translate = ['ì œëª©', 'ë³¸ë¬¸', 'ì£¼ìš” í‚¤ì›Œë“œ'] \n",
    "            for col in header:\n",
    "                translated_headers.append(col)\n",
    "                if col in cols_to_translate:\n",
    "                    translated_headers.append(f\"{col}_en\") \n",
    "            \n",
    "            print(\"Initializing row iterator...\")\n",
    "            rows_iterator = sheet.iter_rows(min_row=2, values_only=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"!!!!!!!! ERROR: ì—‘ì…€ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ !!!!!!!!\")\n",
    "            traceback.print_exc()\n",
    "            print(f\"Skipping this file: {file_basename}\")\n",
    "            continue \n",
    "\n",
    "        else:\n",
    "            print(\"âœ… Excel file loaded successfully. Starting row-by-row processing loop...\")\n",
    "            \n",
    "            try:\n",
    "                pd.DataFrame(columns=translated_headers).to_csv(output_file_path, index=False, encoding=\"utf-8-sig\", mode='w')\n",
    "                print(f\"Output file header written to {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"!!!!!!!! ERROR: Output file Csv write error {e} !!!!!!!!\")\n",
    "                print(f\"Skipping this file: {file_basename}\")\n",
    "                continue \n",
    "                \n",
    "            row_counter = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    row = next(rows_iterator)\n",
    "                    row_counter += 1\n",
    "                    print(f\"\\n--- Processing {file_basename} - Row ID: {row_counter} ---\")\n",
    "                    \n",
    "                    row_data = dict(zip(header, row))\n",
    "                    translated_row_output = {}\n",
    "\n",
    "                    for col_name, col_value in row_data.items():\n",
    "                        translated_row_output[col_name] = col_value\n",
    "                        \n",
    "                        if col_name in cols_to_translate:\n",
    "                            print(f\"  - Translating '{col_name}'...\")\n",
    "                            translated_text = translate_single(col_value)\n",
    "                            translated_row_output[f\"{col_name}_en\"] = translated_text\n",
    "                    \n",
    "                    output_df = pd.DataFrame([translated_row_output], columns=translated_headers)\n",
    "                    output_df.to_csv(output_file_path, index=False, encoding=\"utf-8-sig\", mode='a', header=False)\n",
    "                    print(f\"Row {row_counter} appended to CSV.\")\n",
    "\n",
    "                except StopIteration:\n",
    "                    print(f\"\\n--- Reached end of file: {file_basename} ---\")\n",
    "                    break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"!!!!!!!! ERROR processing row {row_counter} in {file_basename} !!!!!!!!\")\n",
    "                    traceback.print_exc()\n",
    "                    with open(ERROR_LOG_PATH, \"a\", encoding='utf-8') as f:\n",
    "                        f.write(f\"File: {file_basename}\\nFailed processing row {row_counter}\\nError: {e}\\n\\n\")\n",
    "\n",
    "                finally:\n",
    "                    if 'row_data' in locals(): del row_data\n",
    "                    if 'translated_row_output' in locals(): del translated_row_output\n",
    "                    if 'output_df' in locals(): del output_df\n",
    "                    gc.collect() \n",
    "            \n",
    "            print(f\"\\n--- Finished file: {file_basename}. Total rows: {row_counter} ---\")\n",
    "    \n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"--- All files processed ---\")\n",
    "    print(f\"Check {KOR_DATA_DIR} for translated CSV files.\")\n",
    "    print(f\"Check {ERROR_LOG_PATH} for any errors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
